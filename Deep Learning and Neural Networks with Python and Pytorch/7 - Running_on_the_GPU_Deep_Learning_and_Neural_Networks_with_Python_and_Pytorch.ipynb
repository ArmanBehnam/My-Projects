{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Running on the GPU - Deep Learning and Neural Networks with Python and Pytorch p.7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Running on the GPU - Deep Learning and Neural Networks with Python and Pytorch p.7"
      ],
      "metadata": {
        "id": "oFHwvwDvJeUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tutorial is assuming you have access to a GPU either locally or in the cloud. If you need a tutorial covering cloud GPUs and how to use them check out: Cloud GPUs compared and how to use them.\n",
        "\n",
        "If you're using a server, you will want to grab the data, extract it, and get jupyter notebook:"
      ],
      "metadata": {
        "id": "RcVid2fMJkde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
        "!sudo apt-get install unzip\n",
        "!unzip kagglecatsanddogs_3367a.zip\n",
        "!pip3 install jupyterlab"
      ],
      "metadata": {
        "id": "ismz8aI6Jc4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What you can do is just visit the above url, replacing 127.0.0.1 with your server's ip.\n",
        "\n",
        "Code where we left off:"
      ],
      "metadata": {
        "id": "3l6Ylv0yJtb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "REBUILD_DATA = True # set to true to one once, then back to false unless you want to change something in your training data.\n",
        "\n",
        "class DogsVSCats():\n",
        "    IMG_SIZE = 50\n",
        "    CATS = \"PetImages/Cat\"\n",
        "    DOGS = \"PetImages/Dog\"\n",
        "    TESTING = \"PetImages/Testing\"\n",
        "    LABELS = {CATS: 0, DOGS: 1}\n",
        "    training_data = []\n",
        "\n",
        "    catcount = 0\n",
        "    dogcount = 0\n",
        "\n",
        "    def make_training_data(self):\n",
        "        for label in self.LABELS:\n",
        "            print(label)\n",
        "            for f in tqdm(os.listdir(label)):\n",
        "                if \"jpg\" in f:\n",
        "                    try:\n",
        "                        path = os.path.join(label, f)\n",
        "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                        self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot \n",
        "                        #print(np.eye(2)[self.LABELS[label]])\n",
        "\n",
        "                        if label == self.CATS:\n",
        "                            self.catcount += 1\n",
        "                        elif label == self.DOGS:\n",
        "                            self.dogcount += 1\n",
        "\n",
        "                    except Exception as e:\n",
        "                        pass\n",
        "                        #print(label, f, str(e))\n",
        "\n",
        "        np.random.shuffle(self.training_data)\n",
        "        np.save(\"training_data.npy\", self.training_data)\n",
        "        print('Cats:',dogsvcats.catcount)\n",
        "        print('Dogs:',dogsvcats.dogcount)\n",
        "\n",
        "if REBUILD_DATA:\n",
        "    dogsvcats = DogsVSCats()\n",
        "    dogsvcats.make_training_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH4iyCvEHnh3",
        "outputId": "50b23c74-a2ee-4157-b562-20589f59c728"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PetImages/Cat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12501/12501 [00:14<00:00, 841.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PetImages/Dog\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12501/12501 [00:15<00:00, 785.43it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cats: 12476\n",
            "Dogs: 12470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # just run the init of parent class (nn.Module)\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
        "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
        "\n",
        "        x = torch.randn(50,50).view(-1,1,50,50)\n",
        "        self._to_linear = None\n",
        "        self.convs(x)\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\n",
        "        self.fc2 = nn.Linear(512, 2) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
        "\n",
        "    def convs(self, x):\n",
        "        # max pooling over 2x2\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
        "\n",
        "        if self._to_linear is None:\n",
        "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JohaCJcHJzCW",
        "outputId": "ad054bf1-7910-40cd-cf5e-52a44c444a99"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if REBUILD_DATA:\n",
        "    dogsvcats = DogsVSCats()\n",
        "    dogsvcats.make_training_data()\n",
        "\n",
        "training_data = np.load(\"training_data.npy\", allow_pickle=True)\n",
        "print(len(training_data))\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
        "X = X/255.0\n",
        "y = torch.Tensor([i[1] for i in training_data])\n",
        "\n",
        "VAL_PCT = 0.1  # lets reserve 10% of our data for validation\n",
        "val_size = int(len(X)*VAL_PCT)\n",
        "\n",
        "train_X = X[:-val_size]\n",
        "train_y = y[:-val_size]\n",
        "\n",
        "test_X = X[-val_size:]\n",
        "test_y = y[-val_size:]\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "EPOCHS = 1\n",
        "\n",
        "\n",
        "def train(net):\n",
        "    for epoch in range(EPOCHS):\n",
        "        for i in tqdm(range(0, len(train_X), BATCH_SIZE)): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
        "            #print(f\"{i}:{i+BATCH_SIZE}\")\n",
        "            batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
        "            batch_y = train_y[i:i+BATCH_SIZE]\n",
        "\n",
        "            net.zero_grad()\n",
        "\n",
        "            outputs = net(batch_X)\n",
        "            loss = loss_function(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()    # Does the update\n",
        "\n",
        "        print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
        "\n",
        "\n",
        "def test(net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(len(test_X))):\n",
        "            real_class = torch.argmax(test_y[i])\n",
        "            net_out = net(test_X[i].view(-1, 1, 50, 50))[0]  # returns a list, \n",
        "            predicted_class = torch.argmax(net_out)\n",
        "\n",
        "            if predicted_class == real_class:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "    print(\"Accuracy: \", round(correct/total, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxqtP73JIgjm",
        "outputId": "e36a4660-ca84-4742-adee-06452ab7d5bb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PetImages/Cat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12501/12501 [00:14<00:00, 851.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PetImages/Dog\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12501/12501 [00:15<00:00, 801.92it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cats: 12476\n",
            "Dogs: 12470\n",
            "49892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I went ahead and made a quick function to handle the training, mostly since I didn't want to run the training bit again just yet. What I want to talk about now instead is how we go about running things on the GPU.\n",
        "\n",
        "To start, you will need the GPU version of Pytorch. In order to use Pytorch on the GPU, you need a higher end NVIDIA GPU that is CUDA enabled.\n",
        "\n",
        "If you do not have one, there are cloud providers. Linode is both a sponsor of this series as well as they simply have the best prices at the moment on cloud GPUs, by far.\n",
        "\n",
        "Here's a Tutorial for setting up cloud GPUs. You could use the same commands from that tutorial if you're running Ubuntu 16.04 locally.\n",
        "\n",
        "If you're on Windows, or some other OS, the requirements to getting CUDA setup are the same.\n",
        "\n",
        "You need to install the CUDA toolkit.\n",
        "\n",
        "After that, you need to download and extract CuDNN, moving the CuDNN contents into your Cuda Toolkit directory. When you've extracted the CuDNN download, you will have 3 directories inside of a directory called cuda. You just need to move the bin, include, and lib directories and merge them into your Cuda Toolkit directory. For example, for me, my CUDA toolkit directory is: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0, so this is where I would merge those CuDNN directories too.\n",
        "\n",
        "Once you've done that, make sure you have the GPU version of Pytorch too, of course. When you go to the get started page, you can find the topin for choosing a CUDA version.\n",
        "\n",
        "I believe you can also use Anaconda to install both the GPU version of Pytorch as well as the required CUDA packages. I personally don't enjoy using the Conda environment, but this is also an option.\n",
        "\n",
        "Finally, if you're having trouble, come join us in the Sentdex discord. It's really quite simple (download/install CUDA Toolkit and drag and drop the CuDNN files) ... but this can still be daunting to someone unfamiliar with this, as well as certain issues that can still arise. We'd be happy to help you out in our community discord!\n",
        "\n",
        "Once you think you've got everything setup, make sure CUDA is available:"
      ],
      "metadata": {
        "id": "yARG_xaoIx4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzkJJRP5Ilkd",
        "outputId": "40aac2bd-72de-4bb4-cafa-e37142ebecfe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're ready to decide what we want to do on the GPU. We know at the very least we want our model and its calculations to be done on the GPU.\n",
        "\n",
        "If your model is on the GPU, this means, in order to pass data through it, we also want our data on the GPU.\n",
        "\n",
        "Thus, we want not only the model, but also the training data (if it can be fit), all on the GPU.\n",
        "\n",
        "To start, we can put our network on our GPU. To do this, we can just set a flag like:"
      ],
      "metadata": {
        "id": "KnWFFr_uI3vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taNHGqQLItRA",
        "outputId": "f4b4d35b-c4ff-4211-c4ec-8310c4c0b167"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Often, however, we want to write code that allows for a variety of people to use our code, including those who may not have a GPU available. To handle for this, we can use the above torch.cuda.is_available() and do:"
      ],
      "metadata": {
        "id": "ylELvIYrI3GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG-x3BInI7v9",
        "outputId": "235d4e0a-2940-40b9-e967-08e5ca4a509a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on the GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most basic neural networks wont benefit much from multiple GPUs, but, as you progress, you may find that you'd like to use multiple GPUs for your task. Again, to write code that can logically use what's available, you can get how many GPUs are available by doing:"
      ],
      "metadata": {
        "id": "jWeG0V59I_LF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayFJes1YI9l3",
        "outputId": "86cdc7e1-bffc-4b39-ee38-24eeb71fb095"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From here, we could extrapolate out index numbers and assign specific layers to specific GPUs.\n",
        "\n",
        "For now, we're writing code that really just needs either one GPU or CPU, so we'll just use a single device. Now that we have figured out the best device to use, we can start setting things to that device. For example, setting our neural network to that device is as easy as:"
      ],
      "metadata": {
        "id": "t7iKcgyyJDHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuIekSy_JBfN",
        "outputId": "c6ddd052-f3bf-4b9b-a566-cd073e746d51"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We alread had our net defined above, but, usually you'd just immediately define and send it to the device, like:"
      ],
      "metadata": {
        "id": "0WvKzdHVJDfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net().to(device)"
      ],
      "metadata": {
        "id": "B08l08F5JGga"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can go to train, but this time, let's put our batches on the GPU. In this example, we could actually have put all of our data on the GPU, since it's not a huge dataset. This would save with some IO time moving things from RAM to VRAM, But this wont be a very common, so I'd rather just show the way you're going to normally have to most likely do it.\n",
        "\n",
        "I am going to copy the above train function and then make really just one quick modification, which is, after we've defined our batches, we can move them to the GPU by doing: batch_X, batch_y = batch_X.to(device), batch_y.to(device). So now our train function is:"
      ],
      "metadata": {
        "id": "dNpI2WiQJMQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 3\n",
        "\n",
        "def train(net):\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "    BATCH_SIZE = 100\n",
        "    EPOCHS = 3\n",
        "    for epoch in range(EPOCHS):\n",
        "        for i in range(0, len(train_X), BATCH_SIZE): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
        "            #print(f\"{i}:{i+BATCH_SIZE}\")\n",
        "            batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
        "            batch_y = train_y[i:i+BATCH_SIZE]\n",
        "\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "            net.zero_grad()\n",
        "\n",
        "            optimizer.zero_grad()   # zero the gradient buffers\n",
        "            outputs = net(batch_X)\n",
        "            loss = loss_function(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()    # Does the update\n",
        "\n",
        "        print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
        "\n",
        "train(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lErDyyDNJJ5m",
        "outputId": "c16af381-65e4-4509-dc6a-094546bb4c26"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0. Loss: 0.1670691817998886\n",
            "Epoch: 1. Loss: 0.04387164115905762\n",
            "Epoch: 2. Loss: 0.026407744735479355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see by running times, this is much faster. Now we can also test on either the GPU or CPU. Since we're testing on quite a few samples, we can also do this on the GPU:"
      ],
      "metadata": {
        "id": "Ie5PBxTlJRr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_X.to(device)\n",
        "test_y.to(device)\n",
        "\n",
        "def test(net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(len(test_X))):\n",
        "            real_class = torch.argmax(test_y[i]).to(device)\n",
        "            net_out = net(test_X[i].view(-1, 1, 50, 50).to(device))[0]  # returns a list, \n",
        "            predicted_class = torch.argmax(net_out)\n",
        "\n",
        "            if predicted_class == real_class:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "    print(\"Accuracy: \", round(correct/total, 3))\n",
        "\n",
        "test(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRHO0ou6JPfe",
        "outputId": "c80f6d11-7091-486c-b819-8e19254e5e10"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4989/4989 [00:11<00:00, 434.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test in batches faster:\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "for i in tqdm(range(0, len(test_X), BATCH_SIZE)):\n",
        "\n",
        "    batch_X = test_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50).to(device)\n",
        "    batch_y = test_y[i:i+BATCH_SIZE].to(device)\n",
        "    batch_out = net(batch_X)\n",
        "\n",
        "    out_maxes = [torch.argmax(i) for i in batch_out]\n",
        "    target_maxes = [torch.argmax(i) for i in batch_y]\n",
        "    for i,j in zip(out_maxes, target_maxes):\n",
        "        if i == j:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "print(\"Accuracy: \", round(correct/total, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwUHmG5jJWym",
        "outputId": "3685d70d-09e3-417a-e08d-5c6f660c0143"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:00<00:00, 55.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}